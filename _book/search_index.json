[["data-processing-qr-data.html", "Data Processing - Visits &amp; QR Chapter 1 Data Processing - QR Data", " Data Processing - Visits &amp; QR John F. Adamek 2020-11-03 Chapter 1 Data Processing - QR Data Downloading Raw files from Qualtrics Downloaded the raw data files from Qualtrics: Projects -&gt; Group Class Check-In -&gt; Data &amp; Analysis -&gt; Export &amp; Import -&gt; Export Data -&gt; CSV + Download all fields + Use Choice text Saved as: Qualtrics_raw_without_other_option.csv Projects -&gt; Group Class Check-In  Updated with other option 7/31/17 -&gt; Data &amp; Analysis -&gt; Export &amp; Import -&gt; Export Data -&gt; CSV Download all fields + Use Choice text Saved as: Qualtrics_raw_with_other_option.csv Both files were combined into one file separate sheets Saved as: QR_raw_combined_data_separate_sheets.xlsx Files were then combined into one sheet to be used for data cleaning. A Run column was created of running numbers from 1 to keep track of each individual row and to merge data on in R in later steps. Saved as: Qualtrics_combined_rawdata.xlsx Merged Class column and Class-other option column into 1 in excel Filtered Class column by other. Replaced other with the class indicated. N = 1067 total instances Saved as: Qualtrics_cleaning.xlsx Cleaned extreme outliers in TodaysDate that were errors (e.g., 5/28/1017). Start, End, Recorded Date were used as a basis. All month and days were consistent across the three columns. Example: Saved in: Qualtrics_cleaning.xlsx Data Prep in R QR_step1.R: Loaded Qualtrics_cleaning.xlsx in R for data cleaning: Separated time from date into its own column Identified all instances where recorded date was before todaysdate and replaced todays date with the recorded date (n=135) LOGIC: Since it is highly unlikely people were logging in their class attendance for future dates, its expected that this was a typing error when manually typing todays date thus recorded date was determined to be the actual date of class attendance. Identified all instances where recorded date was after todaysdate. (N=845) Saved as: rafter.csv Two issues to consisder: If MONTH and DAY are the same for start date, end date, recorded date and todays date but YEAR is different in todays date = year was changed to reflect recorded year n = 228 Participants were allowed to report PAST class attendances resulting in instances where there are multiple (as much as 8) logs on a single day (illustrated via start,end,recorded date) with the actual date being manually reported in todays date. All instances that arent satisfied via the first issue above were individually checked and corrected. Saved as: rafter_clean.csv See &lt;- recording_ofme_cleaning_rafter.pptx for more info Because occurrences part of issue 2 would result in TodaysDate remaining the same. No changes were made here Returned back to R to pick up where we left off before bullet point c. **** See r file: QR_step1.R Saved as: QR_cleanned_07312020.csv Opened QR_cleanned_07312020.csv file outside of R In this excel file  created a new column CorrectDate Then condensed Todays Date, r_before, and r_after over to CorrectDate Filtered r_after column by valid dates only(no NAs) -&gt; checked one last time accuracy and then merged to CorrectDate column. Filtered r_before column by valid dates only (no NAs) -&gt; checked one last time accuracy and then merged to CorrectDate column. Filtered TodaysDate column by valid dates only -&gt; checked one last time accuracy and then merged to CorrectDate column. Filtered CorrectDate column by BLANKS -&gt; checked to make sure r_after and r_before columns were all NA and then merged TodaysDate to CorrectDate No issues with the above. This process was checked at the end to ensure no overlap between r_before and r_after columns with CorrectDate Saved as: QR_CorrectDate.csv ##### Pulling in the data ##### setwd(&quot;C:/Users/jadamek2/Desktop/LAB_NUC/QR_data/QR_Cleaning_Processing_Files&quot;) data &lt;- read_excel(&quot;Qualtrics_cleaning.xlsx&quot;) library(tidyr) ##### Formatting and Preparing the data #### # Separates The column by data and time data &lt;- separate(data, StartDate, into=c(&quot;sdate&quot;,&quot;stime&quot;), sep = &quot; &quot;) data &lt;- separate(data, EndDate, into=c(&quot;Edate&quot;,&quot;Etime&quot;), sep = &quot; &quot;) data &lt;- separate(data, RecordedDate, into=c(&quot;Rdate&quot;,&quot;Rtime&quot;), sep = &quot; &quot;) # Removes the time columns data &lt;- data[-c(5,7,9)] # Converts class type from chr to date data$sdate &lt;- gsub(&quot;-&quot;,&quot;&quot;, data$sdate) data$Edate &lt;- gsub(&quot;-&quot;,&quot;&quot;, data$Edate) data$Rdate &lt;- gsub(&quot;-&quot;,&quot;&quot;, data$Rdate) data$TodaysDate &lt;- gsub(&quot;-&quot;,&quot;&quot;, data$TodaysDate) data$sdate &lt;- as.Date(data$sdate, format=&quot;%Y%m%d&quot;) data$Edate &lt;- as.Date(data$Edate, format=&quot;%Y%m%d&quot;) data$Rdate &lt;- as.Date(data$Rdate, format=&quot;%Y%m%d&quot;) data$TodaysDate &lt;- as.Date(data$TodaysDate, format=&quot;%Y%m%d&quot;) ##### Cleaning the Data for instances where Today&#39;s Date and Recorded Date does not match #### # Identifies which Recorded dates are before Todays dates and changes Todays Date to Recorded Date R_before &lt;- with(data, data[Rdate &lt; TodaysDate, ]) R_before$TodaysDate &lt;- R_before$Rdate # Identifies which Recorded dates are before Todays dates R_after &lt;- with(data, data[Rdate &gt; TodaysDate, ]) # Saves this file to csv. to manually check for whether these were errors in typing the date or not (see data processing steps and/or screen recording) write.csv(R_after, &quot;rafter.csv&quot;) # Imports the cleanned rafter file R_after_cl &lt;- read.csv(&quot;rafter_clean.csv&quot;) # This matches the data on RUN and merges data from R_before and R_after_cl into main data set with others data$r_before &lt;- R_before$TodaysDate[match(data$Run, R_before$Run)] data$r_after &lt;- R_after_cl$TodaysDate[match(data$Run, R_after_cl$Run)] # Writes the data to file write.csv(data, &quot;QR_cleanned_07312020.csv&quot;) ##### End of Step 1: Notes to be done before opening QR_step2.R #### # After this process I opened the new csv file to ensure accuracy by checking the columns: r_before and r_after # The changed dates were then merged into a final CorrectDate column. # When this is completed I continued data cleaning in QR_ID_cleanning QR_step2.R: This csv file (QR_CorrectDate.csv) was then loaded into r: Dates were separated by month, day, and year and then tallied for all 12 months Afterwards the IDs were assigned to their appropriate wave After running this function from the total dataset (obs = 7276) each wave had: Wave 1 = 1841 obs Wave 2 = 1704 obs -&gt; 1705 after correcting (see below) Wave 3 = 1389 obs Wave 4 = 518 obs Wave 5 = 811 obs -&gt; 812 after correcting (see below) Wave 6 = 1003 obs -&gt; 1004 after correcting (see below) This totals 7266obs The missing 10 observations were: ID 593 = 3x *IPaddress not found ID 365 = 2x *IPaddress universal ID 352 = 1x *IPaddress universal ID 346 = 1x *Determined to be ID342 after looking up IPaddress ID 286 = 1x *Determined to be ID296 after looking up IPaddress ID 270 = 1x *Determined to be ID170 after looking up IPaddress ID 203 = 1x *IPaddress not found Each wave (with combined IDs) was then saved into their folder (e.g., Wave1) as a csv (e.g., wave1_qr.csv) Each Individual ID was also saved into their Wave folder (e.g ID259.csv) There were instances where participants kept logging their class attendance after the 12-month frame (e.g., wave 1, ID101 logged class attended on 3/4/2018  but wave1 ended 1/31/2018). Each waves combined file was opened (e.g., wave1_qr.csv) and all data AFTER the 12-month dataframe was removed. This was then saved with clean at the end (e.g., wave1_qr_clean.csv) so that the original file was not modified which contained the data outside of the 12-month time frame Wave 1 = 40 instances IDs: 101, 128, 132, 134, 141, ,143, 158 Wave 2 = 5 instances (ID204 was determined to be ID294[wave5] based on date, IPAddress, and class type) IDs 156, 172, 183 Wave 3 = 11 instances (ID232 was changed from 11/7/2017 to 11/7/2018) IDs: 215, 217, 221, 223, 243, 244 Wave 4 = 5 instances IDs: 259, 288 Wave 5 = 3 instances (ID 306 was changed from 3/23/2018 to 3/26/2019) ID: 296 Wave 6 = 85 instances (April&amp;May removed due to refinery being closed) *Due to COVID-19 many participants logged classes they attended at home, yard work, neighborhood walking, etc. ID326 changed from 6/3/2018 to 6/5/2019 ID342 changed from 9/19/2018 to 9/20/2019 *BEFORE ANY REMOVING, DATA WAS VERIFIED WITH RAW DATAFILE (QR_raw_combined_data_separate_sheets.xlsx) ##### Libraries ##### library(tidyr) library(haven) library(dplyr) ##### Pulling in the data #### setwd(&quot;C:/Users/jadamek2/Desktop/LAB_NUC/QR_data/QR_Cleaning_Processing_Files&quot;) data &lt;- read.csv(&quot;QR_CorrectDate.csv&quot;) data &lt;- data[c(1,2,3,10)] ##### Formatting and Preparing the data #### # This uses the separate function to separate the date by month, day, and year new = separate(data, col = CorrectDate, into = c(&quot;Month&quot;,&quot;Day&quot;, &quot;Year&quot;), sep = &quot;/&quot;) # This tallys their attendance (via class attendence) per month new$feb &lt;- ifelse(new$Month == 2, 1, 0) new$mar &lt;- ifelse(new$Month == 3, 1, 0) new$apr &lt;- ifelse(new$Month == 4, 1, 0) new$may &lt;- ifelse(new$Month == 5, 1, 0) new$june &lt;- ifelse(new$Month == 6, 1, 0) new$july &lt;- ifelse(new$Month == 7, 1, 0) new$aug &lt;- ifelse(new$Month == 8, 1, 0) new$sep &lt;- ifelse(new$Month == 9, 1, 0) new$oct &lt;- ifelse(new$Month == 10, 1, 0) new$nov &lt;- ifelse(new$Month == 11, 1, 0) new$dec &lt;- ifelse(new$Month == 12, 1, 0) new$jan &lt;- ifelse(new$Month == 1, 1, 0) # ID&#39;s filtered by Waves wave1 &lt;- c(100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 131, 132, 134, 135, 136, 137, 139, 141, 142, 143, 146, 147, 150, 151, 152, 153, 155, 157, 158, 161, 162) wave2 &lt;- c(133, 138, 144, 149, 154, 156, 159, 160, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 204, 205, 206) wave3 &lt;- c(207, 208, 209, 210, 211, 212, 213, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 237, 238, 239, 240, 241, 242, 243, 244, 245, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258) wave4 &lt;- c(214, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 271, 273, 274, 275, 277, 278, 279, 280, 281, 282, 283, 284, 285, 287, 288, 289, 291) wave5 &lt;- c(292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314) wave6 &lt;- c(316, 317, 318, 319, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 338, 339, 341, 342, 343, 344, 345, 347, 348, 349, 350, 351, 353, 354, 355, 356, 357, 358) # Separating ID&#39;s into their appropriate waves and saves them as raw files by waves wave1_qr &lt;- new[new$ID %in% wave1,] wave2_qr &lt;- new[new$ID %in% wave2,] wave3_qr &lt;- new[new$ID %in% wave3,] wave4_qr &lt;- new[new$ID %in% wave4,] wave5_qr &lt;- new[new$ID %in% wave5,] wave6_qr &lt;- new[new$ID %in% wave6,] write.csv(wave1_qr, &quot;wave1_qr.csv&quot;) write.csv(wave2_qr, &quot;wave2_qr.csv&quot;) write.csv(wave3_qr, &quot;wave3_qr.csv&quot;) write.csv(wave4_qr, &quot;wave4_qr.csv&quot;) write.csv(wave5_qr, &quot;wave5_qr.csv&quot;) write.csv(wave6_qr, &quot;wave6_qr.csv&quot;) ##### Creating separate files for each ID ##### #ID100 &lt;- subset(data, ID == 100) ID101 &lt;- subset(new, ID == 101) ID102 &lt;- subset(new, ID == 102) ID103 &lt;- subset(new, ID == 103) ID104 &lt;- subset(new, ID == 104) ID105 &lt;- subset(new, ID == 105) ID106 &lt;- subset(new, ID == 106) ID107 &lt;- subset(new, ID == 107) ID108 &lt;- subset(new, ID == 108) ID109 &lt;- subset(new, ID == 109) ID110 &lt;- subset(new, ID == 110) ID111 &lt;- subset(new, ID == 111) ID112 &lt;- subset(new, ID == 112) ID113 &lt;- subset(new, ID == 113) ID114 &lt;- subset(new, ID == 114) ID115 &lt;- subset(new, ID == 115) ID116 &lt;- subset(new, ID == 116) ID117 &lt;- subset(new, ID == 117) ID118 &lt;- subset(new, ID == 118) ID120 &lt;- subset(new, ID == 120) ID121 &lt;- subset(new, ID == 121) ID122 &lt;- subset(new, ID == 122) ID123 &lt;- subset(new, ID == 123) ID124 &lt;- subset(new, ID == 124) ID125 &lt;- subset(new, ID == 125) ID126 &lt;- subset(new, ID == 126) ID127 &lt;- subset(new, ID == 127) ID128 &lt;- subset(new, ID == 128) ID129 &lt;- subset(new, ID == 129) ID131 &lt;- subset(new, ID == 131) ID132 &lt;- subset(new, ID == 132) ID133 &lt;- subset(new, ID == 133) ID134 &lt;- subset(new, ID == 134) ID135 &lt;- subset(new, ID == 135) ID136 &lt;- subset(new, ID == 136) ID137 &lt;- subset(new, ID == 137) #ID138 &lt;- subset(data, ID == 138) ID139 &lt;- subset(new, ID == 139) ID141 &lt;- subset(new, ID == 141) ID142 &lt;- subset(new, ID == 142) ID143 &lt;- subset(new, ID == 143) ID144 &lt;- subset(new, ID == 144) ID146 &lt;- subset(new, ID == 146) ID147 &lt;- subset(new, ID == 147) ID149 &lt;- subset(new, ID == 149) #ID150 &lt;- subset(data, ID == 150) ID151 &lt;- subset(new, ID == 151) ID152 &lt;- subset(new, ID == 152) ID153 &lt;- subset(new, ID == 153) ID154 &lt;- subset(new, ID == 154) ID155 &lt;- subset(new, ID == 155) ID156 &lt;- subset(new, ID == 156) ID157 &lt;- subset(new, ID == 157) ID158 &lt;- subset(new, ID == 158) ID159 &lt;- subset(new, ID == 159) #ID160 &lt;- subset(data, ID == 160) ID161 &lt;- subset(new, ID == 161) ID162 &lt;- subset(new, ID == 162) ID167 &lt;- subset(new, ID == 167) #ID168 &lt;- subset(new, ID == 168) ID169 &lt;- subset(new, ID == 169) ID170 &lt;- subset(new, ID == 170) #ID171 &lt;- subset(new, ID == 171) ID172 &lt;- subset(new, ID == 172) ID173 &lt;- subset(new, ID == 173) ID174 &lt;- subset(new, ID == 174) ID175 &lt;- subset(new, ID == 175) ID176 &lt;- subset(new, ID == 176) ID177 &lt;- subset(new, ID == 177) ID178 &lt;- subset(new, ID == 178) ID179 &lt;- subset(new, ID == 179) ID181 &lt;- subset(new, ID == 181) ID182 &lt;- subset(new, ID == 182) ID183 &lt;- subset(new, ID == 183) #ID184 &lt;- subset(new, ID == 184) ID185 &lt;- subset(new, ID == 185) ID186 &lt;- subset(new, ID == 186) ID187 &lt;- subset(new, ID == 187) ID188 &lt;- subset(new, ID == 188) ID189 &lt;- subset(new, ID == 189) ID190 &lt;- subset(new, ID == 190) ID191 &lt;- subset(new, ID == 191) ID192 &lt;- subset(new, ID == 192) ID193 &lt;- subset(new, ID == 193) ID194 &lt;- subset(new, ID == 194) ID195 &lt;- subset(new, ID == 195) ID196 &lt;- subset(new, ID == 196) ID197 &lt;- subset(new, ID == 197) ID198 &lt;- subset(new, ID == 198) ID199 &lt;- subset(new, ID == 199) ID200 &lt;- subset(new, ID == 200) ID201 &lt;- subset(new, ID == 201) ID202 &lt;- subset(new, ID == 202) ID204 &lt;- subset(new, ID == 204) ID205 &lt;- subset(new, ID == 205) ID206 &lt;- subset(new, ID == 206) ID207 &lt;- subset(new, ID == 207) #ID208 &lt;- subset(new, ID == 208) ID209 &lt;- subset(new, ID == 209) ID210 &lt;- subset(new, ID == 210) #ID211 &lt;- subset(new, ID == 211) ID212 &lt;- subset(new, ID == 212) #ID213 &lt;- subset(new, ID == 213) #ID214 &lt;- subset(new, ID == 214) ID215 &lt;- subset(new, ID == 215) ID216 &lt;- subset(new, ID == 216) ID217 &lt;- subset(new, ID == 217) ID218 &lt;- subset(new, ID == 218) ID219 &lt;- subset(new, ID == 219) #ID220 &lt;- subset(new, ID == 220) ID221 &lt;- subset(new, ID == 221) #ID222 &lt;- subset(new, ID == 222) ID223 &lt;- subset(new, ID == 223) ID224 &lt;- subset(new, ID == 224) ID225 &lt;- subset(new, ID == 225) ID226 &lt;- subset(new, ID == 226) ID227 &lt;- subset(new, ID == 227) ID229 &lt;- subset(new, ID == 229) ID230 &lt;- subset(new, ID == 230) ID231 &lt;- subset(new, ID == 231) ID232 &lt;- subset(new, ID == 232) ID233 &lt;- subset(new, ID == 233) ID234 &lt;- subset(new, ID == 234) ID237 &lt;- subset(new, ID == 237) #ID238 &lt;- subset(data, ID == 238) ID239 &lt;- subset(new, ID == 239) ID240 &lt;- subset(new, ID == 240) ID241 &lt;- subset(new, ID == 241) ID242 &lt;- subset(new, ID == 242) ID243 &lt;- subset(new, ID == 243) ID244 &lt;- subset(new, ID == 244) ID245 &lt;- subset(new, ID == 245) ID247 &lt;- subset(new, ID == 247) ID248 &lt;- subset(new, ID == 248) #ID249 &lt;- subset(data, ID == 249) ID250 &lt;- subset(new, ID == 250) #ID251 &lt;- subset(data, ID == 251) ID252 &lt;- subset(new, ID == 252) ID253 &lt;- subset(new, ID == 253) ID254 &lt;- subset(new, ID == 254) ID255 &lt;- subset(new, ID == 255) #ID256 &lt;- subset(new, ID == 256) ID257 &lt;- subset(new, ID == 257) ID258 &lt;- subset(new, ID == 258) ID259 &lt;- subset(new, ID == 259) ID260 &lt;- subset(new, ID == 260) #ID261 &lt;- subset(new, ID == 261) ID262 &lt;- subset(new, ID == 262) ID263 &lt;- subset(new, ID == 263) #ID264 &lt;- subset(new, ID == 264) ID265 &lt;- subset(new, ID == 265) #ID266 &lt;- subset(new, ID == 266) #ID267 &lt;- subset(new, ID == 267) ID268 &lt;- subset(new, ID == 268) ID269 &lt;- subset(new, ID == 269) ID271 &lt;- subset(new, ID == 271) ID273 &lt;- subset(new, ID == 273) #ID274 &lt;- subset(new, ID == 274) ID275 &lt;- subset(new, ID == 275) ID277 &lt;- subset(new, ID == 277) ID278 &lt;- subset(new, ID == 278) ID279 &lt;- subset(new, ID == 279) ID280 &lt;- subset(new, ID == 280) #ID281 &lt;- subset(new, ID == 281) #ID282 &lt;- subset(new, ID == 282) ID283 &lt;- subset(new, ID == 283) ID284 &lt;- subset(new, ID == 284) ID285 &lt;- subset(new, ID == 285) ID287 &lt;- subset(new, ID == 287) ID288 &lt;- subset(new, ID == 288) ID289 &lt;- subset(new, ID == 289) ID291 &lt;- subset(new, ID == 291) #ID292 &lt;- subset(new, ID == 292) ID293 &lt;- subset(new, ID == 293) ID294 &lt;- subset(new, ID == 294) ID295 &lt;- subset(new, ID == 295) ID296 &lt;- subset(new, ID == 296) ID297 &lt;- subset(new, ID == 297) ID298 &lt;- subset(new, ID == 298) ID299 &lt;- subset(new, ID == 299) ID300 &lt;- subset(new, ID == 300) ID301 &lt;- subset(new, ID == 301) ID302 &lt;- subset(new, ID == 302) ID303 &lt;- subset(new, ID == 303) ID304 &lt;- subset(new, ID == 304) ID305 &lt;- subset(new, ID == 305) ID306 &lt;- subset(new, ID == 306) ID307 &lt;- subset(new, ID == 307) #ID308 &lt;- subset(new, ID == 308) #ID309 &lt;- subset(new, ID == 309) ID310 &lt;- subset(new, ID == 310) ID311 &lt;- subset(new, ID == 311) #ID312 &lt;- subset(new, ID == 312) #ID313 &lt;- subset(new, ID == 313) #ID314 &lt;- subset(new, ID == 314) ID316 &lt;- subset(new, ID == 316) ID317 &lt;- subset(new, ID == 317) #ID318 &lt;- subset(new, ID == 318) ID319 &lt;- subset(new, ID == 319) ID321 &lt;- subset(new, ID == 321) ID322 &lt;- subset(new, ID == 322) #ID323 &lt;- subset(new, ID == 323) ID324 &lt;- subset(new, ID == 324) ID325 &lt;- subset(new, ID == 325) ID326 &lt;- subset(new, ID == 326) ID327 &lt;- subset(new, ID == 327) ID328 &lt;- subset(new, ID == 328) ID329 &lt;- subset(new, ID == 329) ID330 &lt;- subset(new, ID == 330) ID331 &lt;- subset(new, ID == 331) ID332 &lt;- subset(new, ID == 332) ID333 &lt;- subset(new, ID == 333) #ID334 &lt;- subset(new, ID == 334) #ID335 &lt;- subset(new, ID == 335) #ID336 &lt;- subset(new, ID == 336) ID338 &lt;- subset(new, ID == 338) #ID339 &lt;- subset(new, ID == 339) ID341 &lt;- subset(new, ID == 341) ID342 &lt;- subset(new, ID == 342) ID343 &lt;- subset(new, ID == 343) ID344 &lt;- subset(new, ID == 344) #ID345 &lt;- subset(new, ID == 345) #ID347 &lt;- subset(new, ID == 347) ID348 &lt;- subset(new, ID == 348) ID349 &lt;- subset(new, ID == 349) ID350 &lt;- subset(new, ID == 350) #ID351 &lt;- subset(new, ID == 351) ID353 &lt;- subset(new, ID == 353) ID354 &lt;- subset(new, ID == 354) ID355 &lt;- subset(new, ID == 355) ID356 &lt;- subset(new, ID == 356) ID357 &lt;- subset(new, ID == 357) #ID358 &lt;- subset(new, ID == 358) ##### Saving individual ID&#39;s to csv file AND folder ##### write.csv(ID101, &quot;ID101.csv&quot;) write.csv(ID102, &quot;ID102.csv&quot;) write.csv(ID103, &quot;ID103.csv&quot;) write.csv(ID104, &quot;ID104.csv&quot;) write.csv(ID105, &quot;ID105.csv&quot;) write.csv(ID106, &quot;ID106.csv&quot;) write.csv(ID107, &quot;ID107.csv&quot;) write.csv(ID108, &quot;ID108.csv&quot;) write.csv(ID109, &quot;ID109.csv&quot;) write.csv(ID110, &quot;ID110.csv&quot;) write.csv(ID111, &quot;ID111.csv&quot;) write.csv(ID112, &quot;ID112.csv&quot;) write.csv(ID113, &quot;ID113.csv&quot;) write.csv(ID114, &quot;ID114.csv&quot;) write.csv(ID115, &quot;ID115.csv&quot;) write.csv(ID116, &quot;ID116.csv&quot;) write.csv(ID117, &quot;ID117.csv&quot;) write.csv(ID118, &quot;ID118.csv&quot;) write.csv(ID120, &quot;ID120.csv&quot;) write.csv(ID121, &quot;ID121.csv&quot;) write.csv(ID122, &quot;ID122.csv&quot;) write.csv(ID123, &quot;ID123.csv&quot;) write.csv(ID124, &quot;ID124.csv&quot;) write.csv(ID125, &quot;ID125.csv&quot;) write.csv(ID126, &quot;ID126.csv&quot;) write.csv(ID127, &quot;ID127.csv&quot;) write.csv(ID128, &quot;ID128.csv&quot;) write.csv(ID129, &quot;ID129.csv&quot;) write.csv(ID131, &quot;ID131.csv&quot;) write.csv(ID132, &quot;ID132.csv&quot;) write.csv(ID133, &quot;ID133.csv&quot;) write.csv(ID134, &quot;ID134.csv&quot;) write.csv(ID135, &quot;ID135.csv&quot;) write.csv(ID136, &quot;ID136.csv&quot;) write.csv(ID137, &quot;ID137.csv&quot;) write.csv(ID139, &quot;ID139.csv&quot;) write.csv(ID141, &quot;ID141.csv&quot;) write.csv(ID142, &quot;ID142.csv&quot;) write.csv(ID143, &quot;ID143.csv&quot;) write.csv(ID144, &quot;ID144.csv&quot;) write.csv(ID146, &quot;ID146.csv&quot;) write.csv(ID147, &quot;ID147.csv&quot;) write.csv(ID149, &quot;ID149.csv&quot;) write.csv(ID151, &quot;ID151.csv&quot;) write.csv(ID152, &quot;ID152.csv&quot;) write.csv(ID154, &quot;ID153.csv&quot;) write.csv(ID154, &quot;ID154.csv&quot;) write.csv(ID155, &quot;ID155.csv&quot;) write.csv(ID156, &quot;ID156.csv&quot;) write.csv(ID157, &quot;ID157.csv&quot;) write.csv(ID158, &quot;ID158.csv&quot;) write.csv(ID159, &quot;ID159.csv&quot;) write.csv(ID161, &quot;ID161.csv&quot;) write.csv(ID162, &quot;ID162.csv&quot;) write.csv(ID167, &quot;ID167.csv&quot;) write.csv(ID169, &quot;ID169.csv&quot;) write.csv(ID170, &quot;ID170.csv&quot;) write.csv(ID172, &quot;ID172.csv&quot;) write.csv(ID173, &quot;ID173.csv&quot;) write.csv(ID174, &quot;ID174.csv&quot;) write.csv(ID175, &quot;ID175.csv&quot;) write.csv(ID176, &quot;ID176.csv&quot;) write.csv(ID177, &quot;ID177.csv&quot;) write.csv(ID178, &quot;ID178.csv&quot;) write.csv(ID179, &quot;ID179.csv&quot;) write.csv(ID181, &quot;ID181.csv&quot;) write.csv(ID182, &quot;ID182.csv&quot;) write.csv(ID183, &quot;ID183.csv&quot;) write.csv(ID185, &quot;ID185.csv&quot;) write.csv(ID186, &quot;ID186.csv&quot;) write.csv(ID187, &quot;ID187.csv&quot;) write.csv(ID188, &quot;ID188.csv&quot;) write.csv(ID189, &quot;ID189.csv&quot;) write.csv(ID190, &quot;ID190.csv&quot;) write.csv(ID191, &quot;ID191.csv&quot;) write.csv(ID192, &quot;ID192.csv&quot;) write.csv(ID193, &quot;ID193.csv&quot;) write.csv(ID194, &quot;ID194.csv&quot;) write.csv(ID195, &quot;ID195.csv&quot;) write.csv(ID196, &quot;ID196.csv&quot;) write.csv(ID197, &quot;ID197.csv&quot;) write.csv(ID198, &quot;ID198.csv&quot;) write.csv(ID199, &quot;ID199.csv&quot;) write.csv(ID200, &quot;ID200.csv&quot;) write.csv(ID201, &quot;ID201.csv&quot;) write.csv(ID202, &quot;ID202.csv&quot;) write.csv(ID204, &quot;ID204.csv&quot;) write.csv(ID205, &quot;ID205.csv&quot;) write.csv(ID206, &quot;ID206.csv&quot;) write.csv(ID207, &quot;ID207.csv&quot;) write.csv(ID209, &quot;ID209.csv&quot;) write.csv(ID210, &quot;ID210.csv&quot;) write.csv(ID212, &quot;ID212.csv&quot;) write.csv(ID215, &quot;ID215.csv&quot;) write.csv(ID216, &quot;ID216.csv&quot;) write.csv(ID217, &quot;ID217.csv&quot;) write.csv(ID218, &quot;ID218.csv&quot;) write.csv(ID219, &quot;ID219.csv&quot;) write.csv(ID221, &quot;ID221.csv&quot;) write.csv(ID223, &quot;ID223.csv&quot;) write.csv(ID224, &quot;ID224.csv&quot;) write.csv(ID225, &quot;ID225.csv&quot;) write.csv(ID226, &quot;ID226.csv&quot;) write.csv(ID227, &quot;ID227.csv&quot;) write.csv(ID229, &quot;ID229.csv&quot;) write.csv(ID230, &quot;ID230.csv&quot;) write.csv(ID231, &quot;ID231.csv&quot;) write.csv(ID232, &quot;ID232.csv&quot;) write.csv(ID233, &quot;ID233.csv&quot;) write.csv(ID234, &quot;ID234.csv&quot;) write.csv(ID237, &quot;ID237.csv&quot;) write.csv(ID239, &quot;ID239.csv&quot;) write.csv(ID240, &quot;ID240.csv&quot;) write.csv(ID241, &quot;ID241.csv&quot;) write.csv(ID242, &quot;ID242.csv&quot;) write.csv(ID243, &quot;ID243.csv&quot;) write.csv(ID244, &quot;ID244.csv&quot;) write.csv(ID245, &quot;ID245.csv&quot;) write.csv(ID247, &quot;ID247.csv&quot;) write.csv(ID248, &quot;ID248.csv&quot;) write.csv(ID250, &quot;ID250.csv&quot;) write.csv(ID252, &quot;ID252.csv&quot;) write.csv(ID253, &quot;ID253.csv&quot;) write.csv(ID254, &quot;ID254.csv&quot;) write.csv(ID255, &quot;ID255.csv&quot;) write.csv(ID257, &quot;ID257.csv&quot;) write.csv(ID258, &quot;ID258.csv&quot;) write.csv(ID259, &quot;ID259.csv&quot;) write.csv(ID260, &quot;ID260.csv&quot;) write.csv(ID262, &quot;ID262.csv&quot;) write.csv(ID263, &quot;ID263.csv&quot;) write.csv(ID265, &quot;ID265.csv&quot;) write.csv(ID268, &quot;ID268.csv&quot;) write.csv(ID269, &quot;ID269.csv&quot;) write.csv(ID271, &quot;ID271.csv&quot;) write.csv(ID273, &quot;ID273.csv&quot;) write.csv(ID275, &quot;ID275.csv&quot;) write.csv(ID277, &quot;ID277.csv&quot;) write.csv(ID278, &quot;ID278.csv&quot;) write.csv(ID279, &quot;ID279.csv&quot;) write.csv(ID280, &quot;ID280.csv&quot;) write.csv(ID283, &quot;ID283.csv&quot;) write.csv(ID284, &quot;ID284.csv&quot;) write.csv(ID285, &quot;ID285.csv&quot;) write.csv(ID287, &quot;ID287.csv&quot;) write.csv(ID288, &quot;ID288.csv&quot;) write.csv(ID289, &quot;ID289.csv&quot;) write.csv(ID291, &quot;ID291.csv&quot;) write.csv(ID293, &quot;ID293.csv&quot;) write.csv(ID294, &quot;ID294.csv&quot;) write.csv(ID295, &quot;ID295.csv&quot;) write.csv(ID296, &quot;ID296.csv&quot;) write.csv(ID297, &quot;ID297.csv&quot;) write.csv(ID298, &quot;ID298.csv&quot;) write.csv(ID299, &quot;ID299.csv&quot;) write.csv(ID300, &quot;ID300.csv&quot;) write.csv(ID301, &quot;ID301.csv&quot;) write.csv(ID302, &quot;ID302.csv&quot;) write.csv(ID303, &quot;ID303.csv&quot;) write.csv(ID304, &quot;ID304.csv&quot;) write.csv(ID305, &quot;ID305.csv&quot;) write.csv(ID306, &quot;ID306.csv&quot;) write.csv(ID307, &quot;ID307.csv&quot;) write.csv(ID310, &quot;ID310.csv&quot;) write.csv(ID311, &quot;ID311.csv&quot;) write.csv(ID316, &quot;ID316.csv&quot;) write.csv(ID317, &quot;ID317.csv&quot;) write.csv(ID319, &quot;ID319.csv&quot;) write.csv(ID321, &quot;ID321.csv&quot;) write.csv(ID322, &quot;ID322.csv&quot;) write.csv(ID324, &quot;ID324.csv&quot;) write.csv(ID325, &quot;ID325.csv&quot;) write.csv(ID326, &quot;ID326.csv&quot;) write.csv(ID327, &quot;ID327.csv&quot;) write.csv(ID328, &quot;ID328.csv&quot;) write.csv(ID329, &quot;ID329.csv&quot;) write.csv(ID330, &quot;ID330.csv&quot;) write.csv(ID331, &quot;ID331.csv&quot;) write.csv(ID332, &quot;ID332.csv&quot;) write.csv(ID333, &quot;ID333.csv&quot;) write.csv(ID338, &quot;ID338.csv&quot;) write.csv(ID341, &quot;ID341.csv&quot;) write.csv(ID342, &quot;ID342.csv&quot;) write.csv(ID343, &quot;ID343.csv&quot;) write.csv(ID344, &quot;ID344.csv&quot;) write.csv(ID348, &quot;ID348.csv&quot;) write.csv(ID349, &quot;ID349.csv&quot;) write.csv(ID350, &quot;ID350.csv&quot;) write.csv(ID353, &quot;ID353.csv&quot;) write.csv(ID354, &quot;ID354.csv&quot;) write.csv(ID355, &quot;ID355.csv&quot;) write.csv(ID356, &quot;ID356.csv&quot;) write.csv(ID357, &quot;ID357.csv&quot;) ##### End of Step 2: Notes to be done before opening QR_step3.R ##### # Next step: Opened each ID&#39;s csv file to check for accuracy and ensure data is within the 12-month window. A couple IDs (i.e., 101) continue # going to the gym after the studies 12-months and future dates needed to be removed QR_step3.R: Each waves clean csv file (e.g., wave1_qr_clean.csv) was loaded into r Data was aggregated and summed so that the resulting file included a single row of each ID with each months class attendance summed for that particular ID A Total class attendance column was created at the end Wave column was added Names of month was changed from jan, feb  into month 1 month 2  This was different for even and odd months  obviously Order of months/columns were reordered Results were then saved for each individual wave as: w1_final.csv In this file some visualization was done for plotting  though this is insignificant for the data processing steps. # Aggregating and formating data # ##### Pulling in the data ##### # Get wave 1 data setwd(&quot;C:/Users/jadamek2/Desktop/LAB_NUC/QR_data/Wave1&quot;) w1_data &lt;- read.csv(&quot;wave1_qr_clean.csv&quot;) # Get wave 2 data setwd(&quot;C:/Users/jadamek2/Desktop/LAB_NUC/QR_data/Wave2&quot;) w2_data &lt;- read.csv(&quot;wave2_qr_clean.csv&quot;) # Get wave 3 data setwd(&quot;C:/Users/jadamek2/Desktop/LAB_NUC/QR_data/Wave3&quot;) w3_data &lt;- read.csv(&quot;wave3_qr_clean.csv&quot;) # Get wave 4 data setwd(&quot;C:/Users/jadamek2/Desktop/LAB_NUC/QR_data/Wave4&quot;) w4_data &lt;- read.csv(&quot;wave4_qr_clean.csv&quot;) # Get wave 5 data setwd(&quot;C:/Users/jadamek2/Desktop/LAB_NUC/QR_data/Wave5&quot;) w5_data &lt;- read.csv(&quot;wave5_qr_clean.csv&quot;) # Get wave 6 data setwd(&quot;C:/Users/jadamek2/Desktop/LAB_NUC/QR_data/Wave6&quot;) w6_data &lt;- read.csv(&quot;wave6_qr_clean.csv&quot;) ##### Preparing and Processing the data to aggregate ##### # The Below codes aggregates each months class attendance by ID. Final variable includes 1 row for each ID with month totals w1_final &lt;- w1_data[-c(1,3,4,5,6)] # Makes dataframe of just the ID&#39;s and months w1_final &lt;- aggregate(.~ID, w1_final, sum) # aggregates total for each month and YTD w1_final$Total_YTD &lt;- rowSums(w1_final[-1]) # This [-1] is to make sure the ID # isn&#39;t summed as well w2_final &lt;- w2_data[-c(1,3,4,5,6)] w2_final &lt;- aggregate(.~ID, w2_final, sum) w2_final$Total_YTD &lt;- rowSums(w2_final[-1]) w3_final &lt;- w3_data[-c(1,3,4,5,6)] w3_final &lt;- aggregate(.~ID, w3_final, sum) w3_final$Total_YTD &lt;- rowSums(w3_final[-1]) w4_final &lt;- w4_data[-c(1,3,4,5,6)] w4_final &lt;- aggregate(.~ID, w4_final, sum) w4_final$Total_YTD &lt;- rowSums(w4_final[-1]) w5_final &lt;- w5_data[-c(1,3,4,5,6)] w5_final &lt;- aggregate(.~ID, w5_final, sum) w5_final$Total_YTD &lt;- rowSums(w5_final[-1]) w6_final &lt;- w6_data[-c(1,3,4,5,6)] w6_final &lt;- aggregate(.~ID, w6_final, sum) w6_final$Total_YTD &lt;- rowSums(w6_final[-1]) # Adds column indicating wave w1_final$wave &lt;- rep(1, nrow(w1_final)) w2_final$wave &lt;- rep(2, nrow(w2_final)) w3_final$wave &lt;- rep(3, nrow(w3_final)) w4_final$wave &lt;- rep(4, nrow(w4_final)) w5_final$wave &lt;- rep(5, nrow(w5_final)) w6_final$wave &lt;- rep(6, nrow(w6_final)) # Labels Month 1, month 2 ... for each wave colnames(w1_final) &lt;- c(&quot;ID&quot;, &quot;Month1&quot;, &quot;Month2&quot;, &quot;Month3&quot;, &quot;Month4&quot;, &quot;Month5&quot;, &quot;Month6&quot;, &quot;Month7&quot;, &quot;Month8&quot;, &quot;Month9&quot;, &quot;Month10&quot;, &quot;Month11&quot;, &quot;Month12&quot;, &quot;YearAVG&quot;, &quot;wave&quot;) colnames(w3_final) &lt;- c(&quot;ID&quot;, &quot;Month1&quot;, &quot;Month2&quot;, &quot;Month3&quot;, &quot;Month4&quot;, &quot;Month5&quot;, &quot;Month6&quot;, &quot;Month7&quot;, &quot;Month8&quot;, &quot;Month9&quot;, &quot;Month10&quot;, &quot;Month11&quot;, &quot;Month12&quot;, &quot;YearAVG&quot;, &quot;wave&quot;) colnames(w5_final) &lt;- c(&quot;ID&quot;, &quot;Month1&quot;, &quot;Month2&quot;, &quot;Month3&quot;, &quot;Month4&quot;, &quot;Month5&quot;, &quot;Month6&quot;, &quot;Month7&quot;, &quot;Month8&quot;, &quot;Month9&quot;, &quot;Month10&quot;, &quot;Month11&quot;, &quot;Month12&quot;, &quot;YearAVG&quot;, &quot;wave&quot;) colnames(w2_final) &lt;- c(&quot;ID&quot;, &quot;Month9&quot;, &quot;Month10&quot;, &quot;Month11&quot;, &quot;Month12&quot;, &quot;Month1&quot;, &quot;Month2&quot;, &quot;Month3&quot;, &quot;Month4&quot;, &quot;Month5&quot;, &quot;Month6&quot;, &quot;Month7&quot;, &quot;Month8&quot;, &quot;YearAVG&quot;, &quot;wave&quot;) colnames(w4_final) &lt;- c(&quot;ID&quot;, &quot;Month9&quot;, &quot;Month10&quot;, &quot;Month11&quot;, &quot;Month12&quot;, &quot;Month1&quot;, &quot;Month2&quot;, &quot;Month3&quot;, &quot;Month4&quot;, &quot;Month5&quot;, &quot;Month6&quot;, &quot;Month7&quot;, &quot;Month8&quot;, &quot;YearAVG&quot;, &quot;wave&quot;) colnames(w6_final) &lt;- c(&quot;ID&quot;, &quot;Month9&quot;, &quot;Month10&quot;, &quot;Month11&quot;, &quot;Month12&quot;, &quot;Month1&quot;, &quot;Month2&quot;, &quot;Month3&quot;, &quot;Month4&quot;, &quot;Month5&quot;, &quot;Month6&quot;, &quot;Month7&quot;, &quot;Month8&quot;, &quot;YearAVG&quot;, &quot;wave&quot;) # Puts Waves 2,4,6 columns in correct order (&quot;month1, month2...) and puts &quot;wave&quot; into the 2nd column position w1_final &lt;- w1_final[c(1,15,2,3,4,5,6,7,8,9,10,11,12,13,14)] w2_final &lt;- w2_final[c(1,15,6,7,8,9,10,11,12,13,2,3,4,5,14)] w3_final &lt;- w3_final[c(1,15,2,3,4,5,6,7,8,9,10,11,12,13,14)] w4_final &lt;- w4_final[c(1,15,6,7,8,9,10,11,12,13,2,3,4,5,14)] w5_final &lt;- w5_final[c(1,15,2,3,4,5,6,7,8,9,10,11,12,13,14)] w6_final &lt;- w6_final[c(1,15,6,7,8,9,10,11,12,13,2,3,4,5,14)] # Creates a master file and saves it master &lt;- rbind(w1_final, w2_final, w3_final, w4_final, w5_final, w6_final) setwd(&quot;C:/Users/jadamek2/Desktop/LAB_NUC/QR_data&quot;) write.csv(master, &quot;QR_master.csv&quot;) # Writes final data as a csv. write.csv(w1_final, &quot;w1_final.csv&quot;) write.csv(w2_final, &quot;w2_final.csv&quot;) write.csv(w3_final, &quot;w3_final.csv&quot;) write.csv(w4_final, &quot;w4_final.csv&quot;) write.csv(w5_final, &quot;w5_final.csv&quot;) write.csv(w6_final, &quot;w6_final.csv&quot;) ########## Visualization ############ data &lt;- master # Taking the mean of each month by wave m1 &lt;- rbind(mean(data$Month1[data$wave == 1]), mean(data$Month1[data$wave == 2]), mean(data$Month1[data$wave == 3]), mean(data$Month1[data$wave == 4]), mean(data$Month1[data$wave == 5]), mean(data$Month1[data$wave == 6])) m2 &lt;- rbind(mean(data$Month2[data$wave == 1]), mean(data$Month2[data$wave == 2]), mean(data$Month2[data$wave == 3]), mean(data$Month2[data$wave == 4]), mean(data$Month2[data$wave == 5]), mean(data$Month2[data$wave == 6])) m3 &lt;- rbind(mean(data$Month3[data$wave == 1]), mean(data$Month3[data$wave == 2]), mean(data$Month3[data$wave == 3]), mean(data$Month3[data$wave == 4]), mean(data$Month3[data$wave == 5]), mean(data$Month3[data$wave == 6])) m4 &lt;- rbind(mean(data$Month4[data$wave == 1]), mean(data$Month4[data$wave == 2]), mean(data$Month4[data$wave == 3]), mean(data$Month4[data$wave == 4]), mean(data$Month4[data$wave == 5]), mean(data$Month4[data$wave == 6])) m5 &lt;- rbind(mean(data$Month5[data$wave == 1]), mean(data$Month5[data$wave == 2]), mean(data$Month5[data$wave == 3]), mean(data$Month5[data$wave == 4]), mean(data$Month5[data$wave == 5]), mean(data$Month5[data$wave == 6])) m6 &lt;- rbind(mean(data$Month6[data$wave == 1]), mean(data$Month6[data$wave == 2]), mean(data$Month6[data$wave == 3]), mean(data$Month6[data$wave == 4]), mean(data$Month6[data$wave == 5]), mean(data$Month6[data$wave == 6])) m7 &lt;- rbind(mean(data$Month7[data$wave == 1]), mean(data$Month7[data$wave == 2]), mean(data$Month7[data$wave == 3]), mean(data$Month7[data$wave == 4]), mean(data$Month7[data$wave == 5]), mean(data$Month7[data$wave == 6])) m8 &lt;- rbind(mean(data$Month8[data$wave == 1]), mean(data$Month8[data$wave == 2]), mean(data$Month8[data$wave == 3]), mean(data$Month8[data$wave == 4]), mean(data$Month8[data$wave == 5]), mean(data$Month8[data$wave == 6])) m9 &lt;- rbind(mean(data$Month9[data$wave == 1]), mean(data$Month9[data$wave == 2]), mean(data$Month9[data$wave == 3]), mean(data$Month9[data$wave == 4]), mean(data$Month9[data$wave == 5]), mean(data$Month9[data$wave == 6])) m10 &lt;- rbind(mean(data$Month10[data$wave == 1]), mean(data$Month10[data$wave == 2]), mean(data$Month10[data$wave == 3]), mean(data$Month10[data$wave == 4]), mean(data$Month10[data$wave == 5]), mean(data$Month10[data$wave == 6])) m11 &lt;- rbind(mean(data$Month11[data$wave == 1]), mean(data$Month11[data$wave == 2]), mean(data$Month11[data$wave == 3]), mean(data$Month11[data$wave == 4]), mean(data$Month11[data$wave == 5]), mean(data$Month11[data$wave == 6])) m12 &lt;- rbind(mean(data$Month12[data$wave == 1]), mean(data$Month12[data$wave == 2]), mean(data$Month12[data$wave == 3]), mean(data$Month12[data$wave == 4]), mean(data$Month12[data$wave == 5]), mean(data$Month12[data$wave == 6])) # Prepare the variables to be plotted wave &lt;- cbind(m1, m2, m3, m4, m5, m6, m7, m8, m9, m10, m11, m12) colnames(wave) &lt;- paste(&quot;Month&quot;, 1:12) rownames(wave) &lt;- paste(&quot;Wave&quot;, 1:6) master &lt;- master[, -c(1,2,15)] monthAVGc &lt;- colMeans(master, na.rm = TRUE) # Plotting the main master plot plot(monthAVGc, main = &quot;Average CLASSES per Month&quot;, xlab = &quot;Months&quot;, ylab = &quot;Average vists&quot;, sub = &quot;Across all waves&quot;, pch = 15, col = &quot;blue&quot;) legend(&quot;topright&quot;,legend=c(&quot;Average across waves&quot;), text.col=c(&quot;black&quot;),pch=c(15),col=c(&quot;blue&quot;)) # Plotting the data par(mfrow=c(2,3)) plot(wave[1,], main = &quot;Wave 1: Average CLASSES per Month&quot;, xlab = &quot;Months&quot;, ylab = &quot;Average CLASSES&quot;, pch = 15, col = &quot;black&quot;) legend(&quot;topright&quot;,legend=c(&quot;January = M12&quot;), text.col=c(&quot;blue&quot;),pch=c(17),col=c(&quot;black&quot;)) axis(1, seq(1,12,1)) plot(wave[3,], main = &quot;Wave 3: Average CLASSES per Month&quot;, xlab = &quot;Months&quot;, ylab = &quot;Average CLASSES&quot;, pch = 15, col = &quot;black&quot;) legend(&quot;topright&quot;,legend=c(&quot;January = M12&quot;), text.col=c(&quot;blue&quot;),pch=c(17),col=c(&quot;black&quot;)) axis(1, seq(1,12,1)) plot(wave[5,], main = &quot;Wave 5: Average CLASSES per Month&quot;, xlab = &quot;Months&quot;, ylab = &quot;Average CLASSES&quot;, pch = 15, col = &quot;black&quot;) legend(&quot;topright&quot;,legend=c(&quot;January = M12&quot;), text.col=c(&quot;blue&quot;),pch=c(17),col=c(&quot;black&quot;)) axis(1, seq(1,12,1)) plot(wave[2,], main = &quot;Wave 2: Average CLASSES per Month&quot;, xlab = &quot;Months&quot;, ylab = &quot;Average CLASSES&quot;, pch = 15, col = &quot;red&quot;) legend(&quot;topright&quot;,legend=c(&quot;January = M8&quot;), text.col=c(&quot;blue&quot;),pch=c(17),col=c(&quot;red&quot;)) axis(1, seq(1,12,1)) plot(wave[4,], main = &quot;Wave 4: Average CLASSES per Month&quot;, xlab = &quot;Months&quot;, ylab = &quot;Average CLASSES&quot;, pch = 15, col = &quot;red&quot;) legend(&quot;topright&quot;,legend=c(&quot;January = M8&quot;), text.col=c(&quot;blue&quot;),pch=c(17),col=c(&quot;red&quot;)) axis(1, seq(1,12,1)) plot(wave[6,], main = &quot;Wave 6: Average CLASSES per Month&quot;, xlab = &quot;Months&quot;, ylab = &quot;Average CLASSES&quot;, pch = 15, col = &quot;red&quot;) legend(&quot;topright&quot;,legend=c(&quot;Covid: M11 &amp; M12&quot;), text.col=c(&quot;blue&quot;),pch=c(17),col=c(&quot;red&quot;)) axis(1, seq(1,12,1)) QR_classes.R: Each waves clean csv file (e.g., wave1_qr_clean.csv) was loaded into r wave column was added and names of month was changed -&gt; see c. and d. above SIDE NOTE: The reason for repeating these two steps again is that it made it easier to aggregate the data first, then performed c. and d. in QR_step3.R In this step, we dont want to work with the aggregated data so were pulling in the non-modified csv file (e.g., wave1_qr_clean.csv) and thus have to repeat those 2 data cleaning steps. Waves were then bind together for a master file containing all 6 waves. Saved as: QR_master_class.csv Each individual wave was also saved as w1_class.csv QR_master_class.csv: File was open externally and classes were then cleaned for the other responses using rules per SPM: For those with other response  if they did NOT have a keyswipe that day give them a tallied variable that will be used in the future. Neighborhood walking does not count UNLESS it was during COVID time the unique responses for other may have some commonalities. So you can probably break them down COVID time online classes should only list the class or online class. This was all cleaned manually in excel. In total n =357 removed **SEE List of classes removed &amp; recoded.xlsx file to see what was removed and what was recoded Saved as: QR_master_class_cleaned QR_Classes.R: the class cleaned filed above was loaded back into R Two files created: Class count by wave and class count overall Saved as: Class_frequency_bywave.csv Saved as: Class_frequency_overall.csv ##### Libraries ##### library(dplyr) ##### Side Task: Prepare separate file containing only classes ##### # Creates a file containing ID, month, day, year, class for each wave ## Pulls in each waves data setwd(&quot;C:/Users/jadamek2/Desktop/LAB_NUC/QR_data/Wave1&quot;) w1_class &lt;- read.csv(&quot;wave1_qr_clean.csv&quot;) setwd(&quot;C:/Users/jadamek2/Desktop/LAB_NUC/QR_data/Wave2&quot;) w2_class &lt;- read.csv(&quot;wave2_qr_clean.csv&quot;) setwd(&quot;C:/Users/jadamek2/Desktop/LAB_NUC/QR_data/Wave3&quot;) w3_class &lt;- read.csv(&quot;wave3_qr_clean.csv&quot;) setwd(&quot;C:/Users/jadamek2/Desktop/LAB_NUC/QR_data/Wave4&quot;) w4_class &lt;- read.csv(&quot;wave4_qr_clean.csv&quot;) setwd(&quot;C:/Users/jadamek2/Desktop/LAB_NUC/QR_data/Wave5&quot;) w5_class &lt;- read.csv(&quot;wave5_qr_clean.csv&quot;) setwd(&quot;C:/Users/jadamek2/Desktop/LAB_NUC/QR_data/Wave6&quot;) w6_class &lt;- read.csv(&quot;wave6_qr_clean.csv&quot;) # Adds column indicating wave w1_class$wave &lt;- rep(1, nrow(w1_class)) w2_class$wave &lt;- rep(2, nrow(w2_class)) w3_class$wave &lt;- rep(3, nrow(w3_class)) w4_class$wave &lt;- rep(4, nrow(w4_class)) w5_class$wave &lt;- rep(5, nrow(w5_class)) w6_class$wave &lt;- rep(6, nrow(w6_class)) # Puts Waves 2,4,6 columns in correct order (&quot;month1, month2...) and puts &quot;wave&quot; into the 2nd column position w1_class &lt;- w1_class[c(1,2,19,3,4,5,6,7,8,9,10,11,12,13,14,18,16,17,18)] w2_class &lt;- w2_class[c(1,2,19,3,4,5,6,11,12,13,14,15,16,17,18,7,8,9,10)] w3_class &lt;- w3_class[c(1,2,19,3,4,5,6,7,8,9,10,11,12,13,14,18,16,17,18)] w4_class &lt;- w4_class[c(1,2,19,3,4,5,6,11,12,13,14,15,16,17,18,7,8,9,10)] w5_class &lt;- w5_class[c(1,2,19,3,4,5,6,7,8,9,10,11,12,13,14,18,16,17,18)] w6_class &lt;- w6_class[c(1,2,19,3,4,5,6,11,12,13,14,15,16,17,18,7,8,9,10)] # Labels Month 1, month 2 ... for each wave colnames(w1_class) &lt;- c(&quot;run&quot;, &quot;ID&quot;, &quot;wave&quot;, &quot;Class&quot;,&quot;Month&quot;, &quot;day&quot;, &quot;year&quot;, &quot;Month1&quot;, &quot;Month2&quot;, &quot;Month3&quot;, &quot;Month4&quot;, &quot;Month5&quot;, &quot;Month6&quot;, &quot;Month7&quot;, &quot;Month8&quot;, &quot;Month9&quot;, &quot;Month10&quot;, &quot;Month11&quot;, &quot;Month12&quot;) colnames(w3_class) &lt;- c(&quot;run&quot;, &quot;ID&quot;, &quot;wave&quot;, &quot;Class&quot;,&quot;Month&quot;, &quot;day&quot;, &quot;year&quot;, &quot;Month1&quot;, &quot;Month2&quot;, &quot;Month3&quot;, &quot;Month4&quot;, &quot;Month5&quot;, &quot;Month6&quot;, &quot;Month7&quot;, &quot;Month8&quot;, &quot;Month9&quot;, &quot;Month10&quot;, &quot;Month11&quot;, &quot;Month12&quot;) colnames(w5_class) &lt;- c(&quot;run&quot;, &quot;ID&quot;, &quot;wave&quot;, &quot;Class&quot;,&quot;Month&quot;, &quot;day&quot;, &quot;year&quot;, &quot;Month1&quot;, &quot;Month2&quot;, &quot;Month3&quot;, &quot;Month4&quot;, &quot;Month5&quot;, &quot;Month6&quot;, &quot;Month7&quot;, &quot;Month8&quot;, &quot;Month9&quot;, &quot;Month10&quot;, &quot;Month11&quot;, &quot;Month12&quot;) colnames(w2_class) &lt;- c(&quot;run&quot;, &quot;ID&quot;, &quot;wave&quot;, &quot;Class&quot;,&quot;Month&quot;, &quot;day&quot;, &quot;year&quot;, &quot;Month1&quot;, &quot;Month2&quot;, &quot;Month3&quot;, &quot;Month4&quot;, &quot;Month5&quot;, &quot;Month6&quot;, &quot;Month7&quot;, &quot;Month8&quot;, &quot;Month9&quot;, &quot;Month10&quot;, &quot;Month11&quot;, &quot;Month12&quot;) colnames(w4_class) &lt;- c(&quot;run&quot;, &quot;ID&quot;, &quot;wave&quot;, &quot;Class&quot;,&quot;Month&quot;, &quot;day&quot;, &quot;year&quot;, &quot;Month1&quot;, &quot;Month2&quot;, &quot;Month3&quot;, &quot;Month4&quot;, &quot;Month5&quot;, &quot;Month6&quot;, &quot;Month7&quot;, &quot;Month8&quot;, &quot;Month9&quot;, &quot;Month10&quot;, &quot;Month11&quot;, &quot;Month12&quot;) colnames(w6_class) &lt;- c(&quot;run&quot;, &quot;ID&quot;, &quot;wave&quot;, &quot;Class&quot;,&quot;Month&quot;, &quot;day&quot;, &quot;year&quot;, &quot;Month1&quot;, &quot;Month2&quot;, &quot;Month3&quot;, &quot;Month4&quot;, &quot;Month5&quot;, &quot;Month6&quot;, &quot;Month7&quot;, &quot;Month8&quot;, &quot;Month9&quot;, &quot;Month10&quot;, &quot;Month11&quot;, &quot;Month12&quot;) # Creates master dataframe of all waves and tallys them masterclass &lt;- rbind(w1_class, w2_class, w3_class, w4_class, w5_class, w6_class) QR_count_bywave &lt;- masterclass %&gt;% count(wave, Class) ## Saves file to directory ##### setwd(&quot;C:/Users/jadamek2/Desktop/LAB_NUC/QR_data&quot;) write.csv(w1_class, &quot;w1_class.csv&quot;) write.csv(w2_class, &quot;w2_class.csv&quot;) write.csv(w3_class, &quot;w3_class.csv&quot;) write.csv(w4_class, &quot;w4_class.csv&quot;) write.csv(w5_class, &quot;w5_class.csv&quot;) write.csv(w6_class, &quot;w6_class.csv&quot;) write.csv(masterclass, &quot;QR_master_class.csv&quot;) ##### Cleaning the &quot;other&quot; class responses as per SPM rules (see document) #### ## File QR_master_class.csv was open externally and classes were cleaned and saved as: QR_master_class_clean.csv ## See QR_Class_Data_Processing.docx and List of classes removed &amp; recoded.xlsx ##### Importing cleanned class file back in #### setwd(&quot;S:/LAB_Documents/Visits_QR_data/QR_data/QR_Cleaned_Processed_Files&quot;) class_clean &lt;- read.csv(&quot;QR_master_class_cleaned.csv&quot;) QR_count_bywave &lt;- class_clean %&gt;% count(wave, Class) QR_count_overall &lt;- class_clean %&gt;% count(Class) write.csv(QR_count_bywave, &quot;Class_frequency_bywave.csv&quot;) write.csv(QR_count_overall, &quot;Class_frequency_overall.csv&quot;) john &lt;- data.frame(unique(class_clean$Class)) colnames(john) &lt;- &quot;Classes&quot; write.csv(john, &quot;class_Descr.csv&quot;) Seans Note (7/28/20 FLAM): Sean Dont worry about classes 4-hour splits  its invalid with this data due to manual typing in. The 4-hour rule is meant for the visits data "],["data-processing-keyswipes-data.html", "Chapter 2 Data Processing - Keyswipes Data", " Chapter 2 Data Processing - Keyswipes Data In -&gt; CORTEX II/Data/PrimaryData-Attendance+Fitbit/Visit Data\" Opened up each waves raw file Then opened up every individual ID file and added a column for their ID # Checked to make sure all data was refinery check in. Anything else removed (e.g., childcare, corporate, WEST) Saved as: ID101.xlsx Previous raw file was kept as is and placed into Data_Data_visit data (mainly for Tiffs W1) Visits_pre.R Here we loaded in ALL the excel files in a specific folder and then bind them together in one data frame ** Wave3, for some reason this data was received differently from the refinery and is reflected in certain individual files. Use raw file BE FIT Dec  Jan.xls for reference. Files for IDs 208, 211, 213, 222, 251 were deleted due to being blank IDs 232, 224/225, 245, 256 had data in feb/2019 removed Wave4: Files for IDs 214, 264, 282 were deleted due to being blank ##### Libraries ##### library(readxl) library(plyr) # for binding multiple files library(dplyr) library(stringr) # for function str_replace_all ##### Loading in multiple files and binding together #### setwd(&quot;C:/Users/jadamek2/Desktop/Visits/wave1&quot;) wave1 &lt;- list.files(pattern = &quot;*.xlsx&quot;, full.names = T) wave1 &lt;- sapply(wave1, read_excel, simplify=FALSE) %&gt;% bind_rows(.id = &quot;ID&quot;) # binding files together in one dataframe setwd(&quot;C:/Users/jadamek2/Desktop/Visits/wave2&quot;) wave2 &lt;- list.files(pattern = &quot;*.xlsx&quot;, full.names = T) wave2 &lt;- sapply(wave2, read_excel, simplify=FALSE) %&gt;% bind_rows(.id = &quot;Client&quot;) setwd(&quot;C:/Users/jadamek2/Desktop/Visits/wave3&quot;) wave3 &lt;- list.files(pattern = &quot;*.xlsx&quot;, full.names = T) wave3 &lt;- sapply(wave3, read_excel, simplify=FALSE) %&gt;% bind_rows(.id = &quot;Client&quot;) setwd(&quot;C:/Users/jadamek2/Desktop/Visits/wave4&quot;) wave4 &lt;- list.files(pattern = &quot;*.xlsx&quot;, full.names = T) wave4 &lt;- sapply(wave4, read_excel, simplify=FALSE) %&gt;% bind_rows(.id = &quot;Client&quot;) setwd(&quot;C:/Users/jadamek2/Desktop/Visits/wave5&quot;) wave5 &lt;- list.files(pattern = &quot;*.xlsx&quot;, full.names = T) wave5 &lt;- sapply(wave5, read_excel, simplify=FALSE) %&gt;% bind_rows(.id = &quot;Client&quot;) setwd(&quot;C:/Users/jadamek2/Desktop/Visits/wave6&quot;) wave6 &lt;- list.files(pattern = &quot;*.xlsx&quot;, full.names = T) wave6 &lt;- sapply(wave6, read_excel, simplify=FALSE) %&gt;% bind_rows(.id = &quot;Client&quot;) Visits_pre.R: ##### Data cleaning ##### Changed class type for wave1$Date to match other waves Cleaned the ID variable to remove the file name (e.g., ./215.xlsx -&gt; 215) Selected the needed columns (date,time,Id,payment) Selected only visits from Be Fit Study. This ensured that things like childcare, corporate, or WEST swipes were not included in the database Data was saved by wave as: wave1_cleaned.csv File was open ** Notes: ID 285 7/5/2018 less than 4 hours ID 217 3/3/2018 less than 4 hours ID 217 3/17/2018 less than 4 hours ID 218 3/20/2018 less than 4 hours ID 218 3/27/2018 less than 4 hours ID 218 3/29/2018 less than 4 hours ID 218 4/9/2018 less than 4 hours ID 218 4/16/2018 less than 4 hours ID 218 11/26/2018 less than 4 hours ID 229 3/31/2018 less than 4 hours ##### Libraries ##### library(readxl) library(plyr) # for binding multiple files library(dplyr) library(stringr) # for function str_replace_all ##### Data Cleaning #### # Converts class type for Date to character for wave 1 so that its the same as wave 2-6 wave1$Date &lt;- as.character(wave1$Date) # Changes column name from Client to ID colnames(wave2)[5] &lt;- &quot;ID&quot; colnames(wave3)[5] &lt;- &quot;ID&quot; colnames(wave4)[5] &lt;- &quot;ID&quot; colnames(wave5)[5] &lt;- &quot;ID&quot; colnames(wave6)[5] &lt;- &quot;ID&quot; # Clean ID column to only show ID# and not file extension wave1$ID &lt;- gsub(&quot;.*D&quot;,&quot;&quot;, wave1$ID) # Removes everything before the number | gsub =before wave1$ID &lt;- wave1$ID %&gt;% str_replace_all(&#39;\\\\.&#39;, &#39;&#39;) # Removes the period in the column wave1$ID &lt;- sub(&quot;xlsx&quot;,&quot;&quot;, wave1$ID) # Removes everything after the number | sub = after wave2$ID &lt;- gsub(&quot;/&quot;, &quot;&quot;, wave2$ID) # Removes the / before the data wave2$ID &lt;- wave2$ID %&gt;% str_replace_all(&#39;\\\\.&#39;, &#39;&#39;) wave2$ID &lt;- sub(&quot;xlsx&quot;,&quot;&quot;, wave2$ID) wave3$ID &lt;- gsub(&quot;/&quot;,&quot;&quot;, wave3$ID) wave3$ID &lt;- wave3$ID %&gt;% str_replace_all(&#39;\\\\.&#39;, &#39;&#39;) wave3$ID &lt;- sub(&quot;xlsx&quot;,&quot;&quot;, wave3$ID) wave4$ID &lt;- gsub(&quot;/&quot;, &quot;&quot;, wave4$ID) wave4$ID &lt;- wave4$ID %&gt;% str_replace_all(&#39;\\\\.&#39;, &#39;&#39;) wave4$ID &lt;- sub(&quot;xlsx&quot;,&quot;&quot;, wave4$ID) wave5$ID &lt;- gsub(&quot;/&quot;, &quot;&quot;, wave5$ID) wave5$ID &lt;- wave5$ID %&gt;% str_replace_all(&#39;\\\\.&#39;, &#39;&#39;) wave5$ID &lt;- sub(&quot;xlsx&quot;,&quot;&quot;, wave5$ID) wave6$ID &lt;- gsub(&quot;/&quot;, &quot;&quot;, wave6$ID) wave6$ID &lt;- wave6$ID %&gt;% str_replace_all(&#39;\\\\.&#39;, &#39;&#39;) wave6$ID &lt;- sub(&quot;xlsx&quot;,&quot;&quot;, wave6$ID) # Removes the extra noise in the Time column ## (.*) looks for any character 0 or more times until the first space, (?) is what makes it stop at the first space wave1$Time &lt;- gsub(&quot;.*? &quot;, &quot; &quot;, wave1$Time) # Changes column &quot;Check-In Time&quot; to &quot;Time&quot; to remain consistent with the other waves colnames(wave1)[8] &lt;- &quot;Pricing Option&quot; colnames(wave2)[6] &lt;- &quot;Time&quot; colnames(wave3)[6] &lt;- &quot;Time&quot; colnames(wave4)[6] &lt;- &quot;Time&quot; colnames(wave5)[6] &lt;- &quot;Time&quot; colnames(wave6)[6] &lt;- &quot;Time&quot; # Select the needed columns (date,time,ID,Payment) then ensures dataset contains only those in Befit study w1 &lt;- wave1[,c(1,3,2,8)] w1 &lt;- subset(w1, `Pricing Option` == &quot;Be Fit Study&quot;) w2 &lt;- wave2[,c(1,5,6,7)] w2 &lt;- subset(w2, `Pricing Option` == &quot;Be Fit Study&quot;) w3 &lt;- wave3[,c(1,5,6,7)] w3 &lt;- subset(w3, `Pricing Option` == &quot;Be Fit Study&quot;) w4 &lt;- wave4[,c(1,5,6,7)] w4 &lt;- subset(w4, `Pricing Option` == &quot;Be Fit Study&quot;) w5 &lt;- wave5[,c(1,5,6,7)] w5 &lt;- subset(w5, `Pricing Option` == &quot;Be Fit Study&quot;) w6 &lt;- wave6[,c(1,5,6,7)] w6 &lt;- subset(w6, `Pricing Option` == &quot;Be Fit Study&quot;) # Writes the cleaned file to Visits folder setwd(&quot;C:/Users/jadamek2/Desktop/Visits&quot;) write.csv(w1, &quot;wave1_cleaned.csv&quot;) write.csv(w2, &quot;wave2_cleaned.csv&quot;) write.csv(w3, &quot;wave3_cleaned.csv&quot;) write.csv(w4, &quot;wave4_cleaned.csv&quot;) write.csv(w5, &quot;wave5_cleaned.csv&quot;) write.csv(w6, &quot;wave6_cleaned.csv&quot;) Visits_Step1: Checked for IDs that had duplicates and saved those duplicates by wave (e.g., wave1_duplicates.csv) This file was open externally and dates were highlighted in the respectful wave1_cleaned.csv file Dates were removed if &lt;4 hours apart, otherwise they remained the same. Final file was saved as = wave1_final.csv Wave 1 ID 115, 5/27/2017 - removed ID 115, 6/10/2017 - removed ID 115, 6/17/2017 - removed ID 115, 7/1/2017 - removed ID 115, 7/15/2017 - removed ID 115, 7/22/2017 - removed ID 115, 7/29/2017 - removed ID 115, 8/5/2017 - removed ID 115, 8/12/2017 - removed ID 116, 3/27/2017  kept: both &gt;4hrs apart ID 116, 3/29/2017  kept: both &gt;4hrs apart ID 116, 4/3/2017  kept: both &gt;4hrs apart ID 116, 4/12/2017  kept: both &gt;4hrs apart ID 116, 4/24/2017  kept: both &gt;4hrs apart ID 116, 4/26/2017  kept: both &gt;4hrs apart ID 132, 2/4/2017 - removed ID 135, 7/7/2017  kept: both &gt;4hrs apart ID 135, 12/20/2017  kept: both &gt;4hrs apart ID 141, 2/6/2017  kept: both &gt;4hrs apart ID 143, 3/3/2017 - removed ID 143, 3/10/2017 - removed ID 143, 4/14/2017 - removed ID 143, 4/21/2017 - removed ID 143, 5/5/2017 - removed ID 143, 5/12/2017 - removed ID 143, 5/19/2017 - removed ID 143, 6/2/2017 - removed ID 143, 6/16/2017 - removed ID 143, 6/30/2017 - removed ID 143, 7/7/2017 - removed ID 143, 8/4/2017 - removed ID 143, 8/11/2017 - removed ID 143, 8/18/2017 - removed ID 143, 9/1/2017 - removed ID 143, 10/30/2017 - removed ID 143, 11/6/2017 - removed ID 143, 11/13/2017 - removed ID 143, 11/20/2017 - removed ID 143, 11/27/2017 - removed ID 143, 12/4/2017 - removed ID 143, 12/11/2017 - removed ID 143, 12/18/2017 - removed ID 143, 1/8/2018 - removed ID 158, 4/24/2017  kept: both &gt;4hrs apart Wave 2 ID 156, 3/19/2018  kept: both &gt;4hrs apart ID 156, 7/24/2017 - removed ID 156, 8/15/2017 - removed ID 167, 8/8/2017 - removed ID 169, 3/14/2018  kept: both &gt;4hrs apart ID 176, 6/17/2017 - removed ID 177, 9/11/2017  kept: both &gt;4hrs apart ID 177, 9/2/2017 - removed ID 178, 8/3/2017 - removed ID 178, 8/31/2017 - removed ID 179, 6/26/2017 - removed ID 182, 6/29/2017 - removed Wave 3 ID 215, 5/14/2018  kept: both &gt;4hrs apart ID 215, 5/24/2018  kept: both &gt;4hrs apart ID 215, 6/18/2018  kept: both &gt;4hrs apart ID 215, 6/20/2018  kept: both &gt;4hrs apart ID 215, 6/21/2018  kept: both &gt;4hrs apart ID 215, 7/5/2018  kept: both &gt;4hrs apart ID 217, 3/17/2018 - removed ID 217, 3/29/2018  kept: both &gt;4hrs apart ID 217, 3/3/2018 - removed ID 217, 4/2/2018 - removed ID 217, 6/15/2018  kept: both &gt;4hrs apart ID 218, 11/14/2018  kept: both &gt;4hrs apart ID 218, 11/26/2018 - removed ID 218, 3/15/2018  kept: both &gt;4hrs apart ID 218, 3/20/2018 - removed ID 218, 3/27/2018 - removed ID 218, 3/29/2018  removed ID 218, 4/16/2018 - removed ID 218, 4/17/2018  kept: both &gt;4hrs apart ID 218, 4/9/2018 - removed ID 218, 5/21/2018  removed ID 218, 6/12/2018 - removed ID 218, 6/21/2018  kept: both &gt;4hrs apart ID 218, 6/7/2018 - removed ID 218, 8/6/2018  kept: both &gt;4hrs apart ID 224, 3/30/2018 - removed ID 229, 3/31/2018 - removed ID 230, 2/12/2018 - removed ID 230, 2/14/2018  kept: both &gt;4hrs apart ID 230, 2/8/2018  kept: both &gt;4hrs apart ID 232, 11/23/2018  kept: both &gt;4hrs apart ID 232, 3/28/2018  kept: both &gt;4hrs apart ID 232, 4/11/2018  kept: both &gt;4hrs apart ID 233, 3/9/2018  kept: both &gt;4hrs apart ID 248, 1/2/2019  kept: both &gt;4hrs apart ID 254, 3/12/2018  kept: both &gt;4hrs apart ID 254, 3/26/2018  kept: both &gt;4hrs apart ID 254, 4/3/2018  removed ID 256, 2/6/2018 - removed Wave 4/ ID 285, 7/5/2018 - removed Wave 5 ID 306, 2/5/2019  removed ID 306, 3/19/2019 - removed Wave 6 ID 358, 6/20/2019  removed Each wave1_final.csv was checked once again for formatting (date 48256) and 12-month range. Wave1_final.csv is new master type file moving forward library(dplyr) library(tidyr) # Set working directory and read in data setwd(&quot;C:/Users/jadamek2/Desktop/Visits&quot;) wave1 &lt;- read.csv(&quot;wave1_cleaned.csv&quot;) wave2 &lt;- read.csv(&quot;wave2_cleaned.csv&quot;) wave3 &lt;- read.csv(&quot;wave3_cleaned.csv&quot;) wave4 &lt;- read.csv(&quot;wave4_cleaned.csv&quot;) wave5 &lt;- read.csv(&quot;wave5_cleaned.csv&quot;) wave6 &lt;- read.csv(&quot;wave6_cleaned.csv&quot;) # Determining which ID&#39;s have duplicate check-In Dates check &lt;- wave1 %&gt;% group_by(ID,Date) %&gt;% count(Date) w1d &lt;- with(check, check[n &gt; 1, ]) check &lt;- wave2 %&gt;% group_by(ID,Date) %&gt;% count(Date) w2d &lt;- with(check, check[n &gt; 1, ]) check &lt;- wave3 %&gt;% group_by(ID,Date) %&gt;% count(Date) w3d &lt;- with(check, check[n &gt; 1, ]) check &lt;- wave4 %&gt;% group_by(ID,Date) %&gt;% count(Date) w4d &lt;- with(check, check[n &gt; 1, ]) check &lt;- wave5 %&gt;% group_by(ID,Date) %&gt;% count(Date) w5d &lt;- with(check, check[n &gt; 1, ]) check &lt;- wave6 %&gt;% group_by(ID,Date) %&gt;% count(Date) w6d &lt;- with(check, check[n &gt; 1, ]) # Writing file of all duplicate ID&#39;s to be checked write.csv(w1d, &quot;wave1_duplicates.csv&quot;) write.csv(w2d, &quot;wave2_duplicates.csv&quot;) write.csv(w3d, &quot;wave3_duplicates.csv&quot;) write.csv(w4d, &quot;wave4_duplicates.csv&quot;) write.csv(w5d, &quot;wave5_duplicates.csv&quot;) write.csv(w6d, &quot;wave6_duplicates.csv&quot;) ##### See Data Processing Visits.docx 4.c #### # duplicate swipes on same day was checked for 4 hour rule # read in files after removing duplicates #### setwd(&quot;C:/Users/jadamek2/Desktop/Visits&quot;) wave1 &lt;- read.csv(&quot;wave1_final.csv&quot;) wave2 &lt;- read.csv(&quot;wave2_final.csv&quot;) wave3 &lt;- read.csv(&quot;wave3_final.csv&quot;) wave4 &lt;- read.csv(&quot;wave4_final.csv&quot;) wave5 &lt;- read.csv(&quot;wave5_final.csv&quot;) wave6 &lt;- read.csv(&quot;wave6_final.csv&quot;) **** NEXT STEP IS TO MERGE QR AND VISITS TOGETHER BASED ON ID **** "],["data-processing-merging-qr-keyswipe.html", "Chapter 3 Data Processing - Merging QR &amp; Keyswipe", " Chapter 3 Data Processing - Merging QR &amp; Keyswipe Merging data together Read in final visit data from processing sheet (e.g., wave1_final.csv) Added column indicating wave to each individual wave file prior to merging Select columns: ID, Wave, Date, Pricing Option Merged all wave files into new data frame: Visit_Master Renamed Pricing Option -&gt; Keyswipe Recoded Be Fit Study (which indicated a keyswipe) to 1 For QR data, first we needed to import proper date format Read in QR_CorrectDate.csv file Select columns Run and CorrectDate Read in final QR data from processing sheet = QR_master_class_cleaned.csv Merged the CorrectDate column to QR_master_class_cleaned file on the Run column Reordered the dataset to use only whats needed Renamed CorrectDate to Date Recoded Class to 1 Merging Merged QR data and Keyswipe data on ID and Date For all perfectly matching ID and Date this will be shown without any issues For any observation where ID and Date did not match for QR and Keyswipe date =&gt; R will indicate this as NA in the column Saved as: Final_Merged_raw.csv ##### Visits Data ##### # Read in Visits data setwd(&quot;C:/Users/jadamek2/Desktop/LAB_NUC/Visits_QR_data/Visits&quot;) wave1_v &lt;- read.csv(&quot;wave1_final.csv&quot;) wave2_v &lt;- read.csv(&quot;wave2_final.csv&quot;) wave3_v &lt;- read.csv(&quot;wave3_final.csv&quot;) wave4_v &lt;- read.csv(&quot;wave4_final.csv&quot;) wave5_v &lt;- read.csv(&quot;wave5_final.csv&quot;) wave6_v &lt;- read.csv(&quot;wave6_final.csv&quot;) # Adds column indicating wave wave1_v$wave &lt;- rep(1, nrow(wave1_v)) wave2_v$wave &lt;- rep(2, nrow(wave2_v)) wave3_v$wave &lt;- rep(3, nrow(wave3_v)) wave4_v$wave &lt;- rep(4, nrow(wave4_v)) wave5_v$wave &lt;- rep(5, nrow(wave5_v)) wave6_v$wave &lt;- rep(6, nrow(wave6_v)) # Selects columns of interest wave1_v &lt;- wave1_v[c(3,6,2,5)] wave2_v &lt;- wave2_v[c(3,6,2,5)] wave3_v &lt;- wave3_v[c(3,6,2,5)] wave4_v &lt;- wave4_v[c(3,6,2,5)] wave5_v &lt;- wave5_v[c(3,6,2,5)] wave6_v &lt;- wave6_v[c(3,6,2,5)] # Merges all the waves into a single dataset visit_master &lt;- rbind(wave1_v, wave2_v, wave3_v, wave4_v, wave5_v, wave6_v) colnames(visit_master)[4] &lt;- &quot;Keyswipe&quot; # Changes pricing.option column to keyswipes visit_master$Keyswipe &lt;- &quot;1&quot; # Give a value 1 to all valid swipes in dataset "],["cleaning.html", "Chapter 4 Cleaning", " Chapter 4 Cleaning Cleanned wave.x and wave.y columns Wave.x -&gt; Wave Wave.y was deleted All NAs -&gt; Find and replace -&gt; 0 Final cleaned saved as: Final_merged.csv ##### QR Data ##### # Read in QR data - for dates setwd(&quot;C:/Users/jadamek2/Desktop/LAB_NUC/Visits_QR_data/QR_data/QR_Cleaned_Processed_Files&quot;) data &lt;- read.csv(&quot;QR_CorrectDate.csv&quot;) data &lt;- data[c(1, 10)] # Read in QR master cleaned setwd(&quot;C:/Users/jadamek2/Desktop/LAB_NUC/Visits_QR_data/QR_data&quot;) class_clean &lt;- read.csv(&quot;QR_master_class_cleaned.csv&quot;) # Merge date format into QR file qr_merg &lt;- merge(class_clean, data, by.x = &quot;run&quot;, by.y = &quot;Run&quot;) qr_master &lt;- qr_merg[c(2,3,20,4)] colnames(qr_master)[3] &lt;- &quot;Date&quot; qr_master$Class &lt;- &quot;1&quot; # Give a value 1 to all valid class attendence in dataset ##### Merging Visits and QR Data ##### final_merged &lt;- merge(qr_master, visit_master, by = c(&quot;ID&quot;, &quot;Date&quot;), all = TRUE) final_merged &lt;- final_merged[c(1,3,2,4,5,6)] setwd(&quot;C:/Users/jadamek2/Desktop/LAB_NUC/Visits_QR_data&quot;) write.csv(final_merged, &quot;Final_merged_raw.csv&quot;) "],["aggregating.html", "Chapter 5 Aggregating", " Chapter 5 Aggregating Read in Final_merged.csv Selected only Class and Keyswipe column Aggregated Created a total combined column of class + keyswipes Prepared to insert waves again Copied wave 1  6 Ids Ran function to create wave column with correct ID Saved as: Complete_Merged.csv ##### Aggregating ##### # Get Data setwd(&quot;S:/LAB_Documents/Visits_QR_data&quot;) merg &lt;- read.csv(&quot;Final_merged.csv&quot;) # The Below codes aggregates Class and keyswipes merg_select &lt;- merg[-c(2,3)] # Makes dataframe of just the ID&#39;s class and keyswipe merg_select &lt;- aggregate(.~ID, merg_select, sum) merg_select$Total_Combined &lt;- rowSums(merg_select[-1]) # This [-1] is to make sure the ID # isn&#39;t summed as well #Waves&#39;s wave1 &lt;- c(100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 131, 132, 134, 135, 136, 137, 139, 141, 142, 143, 146, 147, 150, 151, 152, 153, 155, 157, 158, 161, 162) wave2 &lt;- c(133, 138, 144, 149, 154, 156, 159, 160, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 204, 205, 206) wave3 &lt;- c(207, 208, 209, 210, 211, 212, 213, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 237, 238, 239, 240, 241, 242, 243, 244, 245, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258) wave4 &lt;- c(214, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 271, 273, 274, 275, 277, 278, 279, 280, 281, 282, 283, 284, 285, 287, 288, 289, 291) wave5 &lt;- c(292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314) wave6 &lt;- c(316, 317, 318, 319, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 338, 339, 341, 342, 343, 344, 345, 347, 348, 349, 350, 351, 353, 354, 355, 356, 357, 358) #Identifing waves again merg_select$wave[merg_select$ID %in% wave1] &lt;- 1 merg_select$wave[merg_select$ID %in% wave2] &lt;- 2 merg_select$wave[merg_select$ID %in% wave3] &lt;- 3 merg_select$wave[merg_select$ID %in% wave4] &lt;- 4 merg_select$wave[merg_select$ID %in% wave5] &lt;- 5 merg_select$wave[merg_select$ID %in% wave6] &lt;- 6 merg_select &lt;- merg_select[c(1,5,2,3,4)] write.csv(merg_select, &quot;Complete_Merged.csv&quot;) "],["unique.html", "Chapter 6 Unique", " Chapter 6 Unique Seans Unique visit request Read in Final_merged.csv Ran ifelse statement indicating that if Class == 1 (valid) AND keyswipe == 0 create a new column (unique_class) indicating 1 otherwise for all other occurrences 0. This was then aggregated Saved as: Complete_Merged_unique.csv Read into SPSS and saved as Total_Classes&amp;Keyswipes.sav setwd(&quot;S:/LAB_Documents/Visits_QR_data&quot;) uniq &lt;- read.csv(&quot;Final_merged.csv&quot;) # If class is 1 but no overlap new column is a 1 otherwise its a 2 uniq$unique_class &lt;- ifelse(uniq$Class == 1 &amp; uniq$Keyswipe == 0, 1, 0) uniq_ &lt;- uniq[-c(2,3)] uniq_ &lt;- aggregate(.~ID, uniq_, sum) write.csv(uniq_, &quot;Complete_Merged_unique.csv&quot;) "]]
